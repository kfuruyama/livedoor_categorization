{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語分割にはJanomeを使用\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "j_t = Tokenizer()\n",
    "\n",
    "\n",
    "def tokenizer_janome(text):\n",
    "    return [tok for tok in j_t.tokenize(text, wakati=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理として正規化をする関数を定義\n",
    "import re\n",
    "\n",
    "\n",
    "def preprocessing_text(text):\n",
    "\n",
    "    # 改行、半角スペース、全角スペースを削除\n",
    "    text = re.sub('\\r', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('　', '', text)\n",
    "    text = re.sub(' ', '', text)\n",
    "\n",
    "    # 特定文字を正規表現で検索しい、消去する\n",
    "    text = re.sub('http://news.livedoor.com/*+0900', '', text) # これがまずいのだろう\n",
    "    \n",
    "    # 数字文字の一律「0」化\n",
    "    text = re.sub(r'[0-9 ０-９]', '0', text)  # 数字\n",
    "\n",
    "    # 記号と数字の除去\n",
    "    # 今回は無視。半角記号,数字,英字\n",
    "    # 今回は無視。全角記号\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理とJanomeの単語分割を合わせた関数を定義する\n",
    "\n",
    "\n",
    "def tokenizer_with_preprocessing(text):\n",
    "    text = preprocessing_text(text)  # 前処理の正規化\n",
    "    ret = tokenizer_janome(text)  # Janomeの単語分割\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 動作確認\n",
    "text_example_01 = \"http://news.livedoor.com/article/detail/6829004/\n",
    "2012-08-15T10:00:00+0900\n",
    "インタビュー：又吉直樹（ピース）「自分に対する女心は、自意識が邪魔をしてわからないんです」\n",
    "　読書好き、考えすぎ、女の子苦手……。数々の内向的な要素を併せ持ち、内向き芸人界のカリスマとして知られる又吉直樹が、映画初主演を果たした。人の心が読めるタバコを手に入れた青年の役を演じた彼も、私生活では女心がわからなくて大いに悩んでいた!?\n",
    "\n",
    "\n",
    "——初めて映画の主演に抜擢されたお気持ちはいかがでしたか？\n",
    "又吉：僕はあんまり芝居とか得意な方ではないので「大丈夫なのかな？」というのが最初の印象でしたね。不安の方が大きくて、監督さんとかプロデューサーの方にも「僕、演技めっちゃ下手ですよ。やめた方がいいんじゃないですか？」って相談したんですけど「又吉くんみたいな役だから大丈夫だよ」って言われて。\n",
    "\n",
    "\n",
    "——素の又吉さんに近い役だったわけですね。\n",
    "又吉：そうですね。「たどたどしくていい」って言われましたから。ただ、実際に撮影が始まってみるとさすがに、「もうちょっとテンション上げてほしい」と言われましたけど（笑）。\n",
    "\n",
    "\n",
    "——テンションが低すぎた、と。\n",
    "又吉：はい。ほんまの自然体で行ったら「もうちょっと大きい声出るかな？」と言われました（笑）。でも、本当に監督さんがすごく良い空気を作ってくれたので、現場の雰囲気は抜群に良かったです。\n",
    "\n",
    "\n",
    "——実際に演じてみて、主人公の宮内正と又吉さんに共通するところはありましたか？\n",
    "又吉：女性の気持ちがわからないっていうところは似てると思いましたね。宮内くんほどではないですけど、昔から女の子が何を考えているのかわからないですし。あと、めったにないことですけど、自分が女性から告白めいたことをされたときに「気付いてると思うけど、ずっと好きだった」と言われたことがあるんです。でも、僕は全然気付いてなくて（笑）。\n",
    "\n",
    "\n",
    "——その予感はなかったんですか？\n",
    "又吉：めっちゃ仲良い子ではあったんですけど、全然気付かなかったですね。ただ、気付いてなかったと言うのはまずいと思って「うすうす気付いてたけど」という雰囲気にしてごまかしたことはあります。女の子って「実はあのとき好きだった」とか、あとになって言ったりするじゃないですか。僕、そんな可能性は微塵も感じてないですからね。そのときに言ってくれてたら、絶対好きになってたのに、って。\n",
    "\n",
    "\n",
    "——今も女性の気持ちはわからないですか？\n",
    "又吉：わかんないです。コンパとかも苦手で。ずっと行ってなかったんですけど、2〜3年前に後輩とコンパらしきものをやってみたことがあるんです。そしたら、そこでずっと僕にケンカを売ってくる女性がいて。大学4年生で、就職活動をしているらしいんですけど、その試験で出た問題を僕に振ってくるんですよ。ちょっと大喜利みたいな内容で「これ、又吉さんだったらどう答えますか？」って。めんどくさいと思いながらも答えていたら、「それ、私も考えてました！」とか言われて。「こいつ、めっちゃ嫌なやつやん」と思ってたんですけど、あとから実は僕に好意を持っていたと聞かされて……。僕は「いや、なんで好意を持ってる相手にそんなことするん？」と思うんですけど、一緒にコンパに行ってた後輩からは「あの感じは一目瞭然でしょう！」って言われました。僕はもう、ほんまにケンカ売られてると思ってたんです。\n",
    "\n",
    "\n",
    "——又吉さんは小説をよくお読みになると思うんですが、そこでは人間の心の機微が描かれているわけじゃないですか。そういう読書経験を積むことで、女心がわかるようになったりはしないですか？\n",
    "又吉：みんなで飲んでるとき、誰が何を考えてるかっていうのはすぐに頭に入ってくるんですよ。「こいつ、退屈してるな」とか、「あの人、ずっとしゃべってないな」とか。子供の頃から、嫌われないように人の顔色ばかりうかがってきたので、それはわかるんです。でも、自分に対する女心は、自意識が邪魔してわからないんです。\n",
    "\n",
    "『全方位型お笑いマガジン　コメ旬』Vol.4\n",
    "又吉直樹のインタビューは、お笑い評論家・ラリー遠田が編集長をつとめる『全方位型お笑いマガジン　コメ旬』Vol.4（キネマ旬報社・刊）に掲載されています。話題のお笑い芸人インタビューがてんこ盛り！\n",
    "Amazonで詳細を見る\n",
    " 1 2\n",
    "\"\n",
    "\n",
    "print(tokenizer_with_preprocessing(text_example_01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 動作確認\n",
    "text_example_02 = \"インタビュー：又吉直樹（ピース）「自分に対する女心は、自意識が邪魔をしてわからないんです」\"\n",
    "\n",
    "print(tokenizer_with_preprocessing(text_example_02))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Datasetの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
    "import torchtext\n",
    "\n",
    "\n",
    "# 文章とラベルの両方に用意します\n",
    "max_length = 256\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
    "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォルダ「data/livedoor_text」から各tsvファイルを読み込みます\n",
    "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/livedoor_text/', train='livedoor_text_train_val.tsv',\n",
    "    test='livedoor_text_test.tsv', format='tsv',\n",
    "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "\n",
    "# 動作確認\n",
    "print('訓練および検証のデータ数', len(train_val_ds))\n",
    "print('1つ目の訓練および検証のデータ', vars(train_val_ds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# torchtext.data.Datasetのsplit関数で訓練データとvalidationデータを分ける\n",
    "\n",
    "train_ds, val_ds = train_val_ds.split(\n",
    "    split_ratio=0.8, random_state=random.seed(1234))\n",
    "\n",
    "# 動作確認\n",
    "print('訓練データの数', len(train_ds))\n",
    "print('検証データの数', len(val_ds))\n",
    "print('1つ目の訓練データ', vars(train_ds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ボキャブラリーの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語学習済みword2vec　by https://github.com/Kyubyong/wordvectors\n",
    "\n",
    "# https://drive.google.com/open?id=0B0ZXk88koS2KMzRjbnE4ZHJmcWM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 一度gensimで読み込んで、word2vecのformatで保存する\n",
    "model = Word2Vec.load('./data/ja/ja.bin')\n",
    "\n",
    "# 保存\n",
    "model.wv.save_word2vec_format('./data/japanese_word2vec_vectors.vec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtextで単語ベクトルとして読み込みます\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "japanese_word2vec_vectors = Vectors(\n",
    "    name='./data/japanese_word2vec_vectors.vec')\n",
    "\n",
    "# 単語ベクトルの中身を確認します\n",
    "print(\"1単語を表現する次元数：\", japanese_word2vec_vectors.dim)\n",
    "print(\"単語数：\", len(japanese_word2vec_vectors.itos)) # 少なくない？？？なんで？？？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル化したバージョンのボキャブラリーを作成します\n",
    "TEXT.build_vocab(train_ds, vectors=japanese_word2vec_vectors, min_freq=1)\n",
    "\n",
    "# ボキャブラリーのベクトルを確認します\n",
    "print(TEXT.vocab.vectors.shape)  \n",
    "TEXT.vocab.vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DataLorderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaderを作成します\n",
    "train_dl = torchtext.data.Iterator(train_ds, batch_size=24, train=True)\n",
    "\n",
    "val_dl = torchtext.data.Iterator(\n",
    "    val_ds, batch_size=24, train=False, sort=False)\n",
    "\n",
    "test_dl = torchtext.data.Iterator(\n",
    "    test_ds, batch_size=24, train=False, sort=False)\n",
    "\n",
    "\n",
    "# 動作確認 \n",
    "batch = next(iter(val_dl))\n",
    "print(batch.Text)\n",
    "print(batch.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築\n",
    "今回はヘッド数6 のTransformer Encoder（6層）で分類を試みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    '''idで示されている単語をベクトルに変換します'''\n",
    "\n",
    "    def __init__(self, text_embedding_vectors):\n",
    "        super(Embedder, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            embeddings=text_embedding_vectors, freeze=True)\n",
    "        # freeze=Trueによりバックプロパゲーションで更新されず変化しなくなります\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_vec = self.embeddings(x)\n",
    "        return x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "im = Image.open(\"./data/imimimim.jpg\")\n",
    "im_list = np.asarray(im)\n",
    "plt.imshow(im_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
    "\n",
    "    def __init__(self, d_model=300, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model  # 単語ベクトルの次元数\n",
    "\n",
    "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成、するための準備\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # GPUが使える場合はGPUへ送る\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2): # i は分散表現の何次元目かを表す\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos /\n",
    "                                          (10000 ** ((2 * (i + 1))/d_model)))\n",
    "\n",
    "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 入力xとPositonal Encodingを足し算する\n",
    "        # xがpeよりも小さいので、大きくする\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Attention(nn.Module):\n",
    "    '''Transformerは本当はマルチヘッドAttentionですが、\n",
    "    分かりやすさを優先しシングルAttentionで実装します'''\n",
    "\n",
    "    def __init__(self, d_model=300):\n",
    "        super().__init__()\n",
    "\n",
    "        # 今回は全結合層で特徴量を変換する\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時に使用する全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Attentionの大きさ調整の変数\n",
    "        self.d_k = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        # Attentionの値を計算する\n",
    "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # ここでmaskを計算。<pad>の位置はattention 0 に。Encoderのmaskのはなし。\n",
    "        mask = mask.unsqueeze(1)\n",
    "        weights = weights.masked_fill(mask == 0, -1e9) #softmax(-無限大) = 0 であるから。\n",
    "        \n",
    "        # softmaxで規格化をする\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # AttentionをValueとかけ算\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "\n",
    "        # 全結合層で特徴量を変換\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadedAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=300, h=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # q, v, k を d_model → d_model 写像\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Embedding/入力次元　と　それをヘッド数で除算したもの\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.d_k = d_model // h\n",
    "        \n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        \n",
    "        bs = q.size(0) #Batchsizeを取っておく\n",
    "        \n",
    "        # d_model → d_model 写像\n",
    "        k = self.k_linear(k) # Batchsize × seq_len × d_model\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "        \n",
    "        # Embed次元においてhead数個に切る。\n",
    "        k = k.view(bs, -1, self.h, self.d_k) # Batchsize × seq_len × heads × d_k\n",
    "        q = q.view(bs, -1, self.h, self.d_k)\n",
    "        v = v.view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # seq_len次元とhead次元を転置\n",
    "        k = k.transpose(1,2) # Batchsize × heads × seq_len × d_k\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "        # k の seq_len次元とd_k次元を転置\n",
    "        k_transpose = k.transpose(-2, -1) # Batchsize × heads × d_k × seq_len \n",
    "        \n",
    "        # logits計算\n",
    "        logits = torch.matmul(q, k_transpose) /  math.sqrt(self.d_k) # Batchsize × heads × seq_len × seq_len\n",
    "        \n",
    "        # logitsにmaskを施す。<pad>の位置はattention_weightが 0 になるよう、予め置換しておくだけ。\n",
    "        mask_unsq1 = mask.unsqueeze(1) # torch.Size([bs, 1, 256]) の bool\n",
    "        mask_unsq2 = mask_unsq1.unsqueeze(1) # torch.Size([bs, 1, 1, 256]) の bool\n",
    "\n",
    "        logits = logits.masked_fill(mask_unsq2 == 0, -1e9) #softmax(-無限大) = 0 であるから。\n",
    "                \n",
    "        # Attention_wights計算\n",
    "        attn = F.softmax(logits, dim=-1) # Batchsize × heads × seq_len × seq_len\n",
    "\n",
    "        # valueをattnで重み付け\n",
    "        scores = torch.matmul(attn, v) # Batchsize × heads × seq_len × d_k\n",
    "        \n",
    "        # seq_len次元とhead次元を転置\n",
    "        scores = scores.transpose(1,2) # Batchsize × seq_len × heads × d_k\n",
    "        \n",
    "        # Embed次元において、異なるheadのscoresをconcat\n",
    "        concat = scores.contiguous().view(bs, -1, self.d_model) # Batchsize × seq_len × d_model\n",
    "        \n",
    "        # concatに全結合層\n",
    "        output = self.out(concat)\n",
    "\n",
    "        \n",
    "        return output, attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#実験用\n",
    "\n",
    "class MultiheadedAttentionExperiment(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=300, h=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # q, v, k を d_model → d_model 写像\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Embedding/入力次元　と　ヘッド数で除算したもの\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.d_k = d_model // h\n",
    "        \n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        \n",
    "        bs = q.size(0) #Batchsizeを取っておく\n",
    "        \n",
    "        # d_model → d_model 写像\n",
    "        k = self.k_linear(k) # Batchsize × seq_len × d_model\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "        \n",
    "        # Embed次元においてhead数個に切る。\n",
    "        k = k.view(bs, -1, self.h, self.d_k) # Batchsize × seq_len × heads × d_k\n",
    "        q = q.view(bs, -1, self.h, self.d_k)\n",
    "        v = v.view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # seq_len次元とhead次元を転置\n",
    "        k = k.transpose(1,2) # Batchsize × heads × seq_len × d_k\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "        # k の seq_len次元とd_k次元を転置\n",
    "        k_transpose = k.transpose(-2, -1) # Batchsize × heads × d_k × seq_len \n",
    "        \n",
    "        # logits計算\n",
    "        logits = torch.matmul(q, k_transpose) /  math.sqrt(self.d_k) # Batchsize × heads × seq_len × seq_len\n",
    "        \n",
    "        # logitsにmaskを施す。<pad>の位置はattention_weightが 0 になるよう、予め置換しておくだけ。\n",
    "        mask_unsq1 = mask.unsqueeze(1) # torch.Size([bs, 1, 256]) の bool\n",
    "        mask_unsq2 = mask_unsq1.unsqueeze(1) # torch.Size([bs, 1, 1, 256]) の bool\n",
    "\n",
    "        logits_masked = logits.masked_fill(mask_unsq2 == 0, -1e9) #softmax(-無限大) = 0 であるから。\n",
    "                \n",
    "        # Attention_wights計算\n",
    "        attn = F.softmax(logits_masked, dim=-1) # Batchsize × heads × seq_len × seq_len\n",
    "\n",
    "        # valueをattnで重み付け\n",
    "        scores = torch.matmul(attn, v) # Batchsize × heads × seq_len × d_k\n",
    "        \n",
    "        # seq_len次元とhead次元を転置\n",
    "        scores_trans = scores.transpose(1,2) # Batchsize × seq_len × heads × d_k\n",
    "        \n",
    "        # Embed次元において、異なるheadのscoresをconcat\n",
    "        concat = scores_trans.contiguous().view(bs, -1, self.d_model) # Batchsize × seq_len × d_model\n",
    "        \n",
    "        # concatを全結合\n",
    "        output = self.out(concat)\n",
    "\n",
    "        \n",
    "        return k, q, v, k_transpose, logits, logits_masked, attn, scores, scores_trans, concat, output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#実験用\n",
    "\n",
    "# ダミーのインプット\n",
    "sample_input = torch.randn([24, 256, 300])\n",
    "# maskの例\n",
    "texts_in_1stbatch = batch.Text[0]\n",
    "input_pad = 1\n",
    "input_mask = (texts_in_1stbatch != input_pad)\n",
    "\n",
    "attnattn  = MultiheadedAttentionExperiment(300)\n",
    "akey, aquery, avalue, ak_transpose, alogits, alogits_masked, aattn, ascores, ascores_trans, aconcat, aoutput = attnattn(sample_input, sample_input, sample_input, input_mask)\n",
    "print(akey.shape)\n",
    "print(aquery.shape)\n",
    "print(avalue.shape)\n",
    "print(ak_transpose.shape)\n",
    "print(alogits.shape) \n",
    "print(alogits_masked.shape)\n",
    "print(aattn.shape)\n",
    "print(ascores.shape)\n",
    "print(ascores_trans.shape)\n",
    "print(aconcat.shape)\n",
    "print(aoutput.shape)\n",
    "\n",
    "print(input_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "bs = 24\n",
    "sl = 256\n",
    "dim_model = 300\n",
    "heads = 6\n",
    "dim_k = dim_model // heads\n",
    "\n",
    "sample_tensor = torch.randn([bs, sl, dim_model])\n",
    "sample_tensor_split = sample_tensor.view(bs, -1, heads, dim_k)\n",
    "sample_tensor_split_headfirst = sample_tensor_split.transpose(1,2)\n",
    "sample_q = sample_k = sample_v = sample_tensor_split_headfirst\n",
    "sample_k_transpose = sample_k.transpose(-2, -1)\n",
    "sample_attn = torch.matmul(sample_q, sample_k_transpose) /  math.sqrt(dim_k)\n",
    "sample_scores = torch.matmul(sample_attn, sample_v)\n",
    "sample_scores_transpose = sample_scores.transpose(1,2)\n",
    "sample_concat = sample_scores_transpose.contiguous().view(bs, -1, dim_model)\n",
    "\n",
    "print(sample_tensor.shape)\n",
    "print(sample_tensor_split.shape)\n",
    "print(sample_q.shape)\n",
    "print(sample_k_transpose.shape)\n",
    "print(sample_attn.shape)\n",
    "print(sample_scores.shape)\n",
    "print(sample_scores_transpose.shape)\n",
    "print(sample_concat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # LayerNormalization層\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "\n",
    "        # Attentionのあとの全結合層2つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, normlized_weights = self.attn(\n",
    "            x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # LayerNormalization層\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # MultiheadedAttention\n",
    "        self.attn = MultiheadedAttention(d_model)\n",
    "\n",
    "        # Attentionのあとの全結合層\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, attn = self.attn(\n",
    "            x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "\n",
    "        return output, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransformerBlockの中身の動作確認\n",
    "\n",
    "# 必要な層をInstantiation\n",
    "norm_one = nn.LayerNorm(300)\n",
    "norm_two = nn.LayerNorm(300)\n",
    "ffn = FeedForward(300)\n",
    "attnattn  = MultiheadedAttention(300)\n",
    "dp_one = nn.Dropout(0.1)\n",
    "dp_two = nn.Dropout(0.1)\n",
    "\n",
    "# ダミーのインプット\n",
    "sample_input = torch.randn([24, 256, 300])\n",
    "# maskの例\n",
    "texts_in_1stbatch = batch.Text[0]\n",
    "input_pad = 1\n",
    "input_mask = (texts_in_1stbatch != input_pad)\n",
    "\n",
    "# 順伝播再現\n",
    "norm1ed = norm_one(sample_input)\n",
    "after_attn, _ = attnattn(norm1ed, norm1ed, norm1ed, input_mask)\n",
    "after_dp1_residual = sample_input + dp_one(after_attn)\n",
    "norm2ed = norm_two(after_dp1_residual)\n",
    "after_ffn = ffn(norm2ed)\n",
    "after_dp2_residual = after_dp1_residual + dp_two(after_ffn)\n",
    "\n",
    "print(input_mask.shape)\n",
    "print(sample_input.shape)\n",
    "print(norm1ed.shape)\n",
    "print(after_attn.shape)\n",
    "print(after_dp1_residual.shape)\n",
    "print(norm2ed.shape)\n",
    "print(after_ffn.shape)\n",
    "print(after_dp2_residual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=300, output_dim=9): # output_dimはコーパスの9カテゴリ\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語<CLS>の特徴量（300次元）を取り出す\n",
    "        out = self.linear(x0)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なTransformerモデルのクラス\n",
    "\n",
    "\n",
    "class TransformerClassification(nn.Module):\n",
    "    '''Transformerでクラス分類させる'''\n",
    "\n",
    "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # モデル構築\n",
    "        self.net1 = Embedder(text_embedding_vectors)\n",
    "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
    "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        self.net3_3 = TransformerBlock(d_model=d_model)\n",
    "        self.net3_4 = TransformerBlock(d_model=d_model)\n",
    "        self.net3_5 = TransformerBlock(d_model=d_model)\n",
    "        self.net3_6 = TransformerBlock(d_model=d_model)\n",
    "\n",
    "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x1 = self.net1(x)  # Embedding\n",
    "        x2 = self.net2(x1)  # PEを加える\n",
    "        x3_1, attn_1 = self.net3_1(x2, mask)  # Transformer block 一段目\n",
    "        x3_2, attn_2 = self.net3_2(x3_1, mask)  # Transformer block 二段目\n",
    "        x3_3, attn_3 = self.net3_3(x3_2, mask)  # Transformer block 三段目\n",
    "        x3_4, attn_4 = self.net3_4(x3_3, mask)  # Transformer block 四段目\n",
    "        x3_5, attn_5 = self.net3_5(x3_4, mask)  # Transformer block 五段目\n",
    "        x3_6, attn_6 = self.net3_6(x3_5, mask)  # Transformer block 六段目\n",
    "\n",
    "        x4 = self.net4(x3_6)  # カテゴリ次元になってるはず。\n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 動作確認\n",
    "\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(train_dl))\n",
    "\n",
    "# モデル構築\n",
    "net = TransformerClassification(\n",
    "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス：\", device)\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "# 入力\n",
    "x = batch.Text[0]\n",
    "# mask作成\n",
    "input_pad = 1\n",
    "input_mask = (x != input_pad)\n",
    "# 出力\n",
    "out, normlized_weights_1, normlized_weights_2 = net(x, input_mask)\n",
    "\n",
    "print(\"出力のテンソルサイズ：\", out.shape)\n",
    "print(\"出力テンソルのsoftmax：\", F.softmax(out, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = batch.Text[0]\n",
    "print(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pad = 1\n",
    "input_mask = (x != input_pad)\n",
    "print(input_mask)\n",
    "input_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sample_tententensor = torch.randn([64, 256, 256]) # Batchsize × seq_len × seq_len (Singleheadedのときのlogits)\n",
    "print(sample_tententensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sample_tentententensor = torch.randn([64, 6, 256, 256]) # Batchsize × head × seq_len × seq_len (Multiheadedのときのlogits)\n",
    "print(sample_tentententensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# logitsにmaskを施す。<pad>の位置はattention_weightが 0 になるよう、予め置換しておくだけ。\n",
    "input_mask_unsq1 = input_mask.unsqueeze(1)\n",
    "input_mask_unsq2 = input_mask_unsq1.unsqueeze(1)\n",
    "\n",
    "print(input_mask_unsq1)\n",
    "print(input_mask_unsq1.shape)\n",
    "print(input_mask_unsq2)\n",
    "print(input_mask_unsq2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sample_tententensor_masked = sample_tententensor.masked_fill(input_mask_unsq1 == 0, -1e9) #softmax(-無限大) = 0 であるから。\n",
    "print(sample_tententensor_masked)\n",
    "print(sample_tententensor_masked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sample_tentententensor_masked = sample_tentententensor.masked_fill(input_mask_unsq2 == 0, -1e9) #softmax(-無限大) = 0 であるから。\n",
    "print(sample_tentententensor_masked)\n",
    "print(sample_tentententensor_masked.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書オブジェクトにまとめる\n",
    "# Batchサイズは24のほう\n",
    "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築\n",
    "net = TransformerClassification(\n",
    "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=9)\n",
    "\n",
    "# ネットワークの初期化を定義\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        # Liner層の初期化\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "# 訓練モードに設定\n",
    "net.train()\n",
    "\n",
    "# TransformerBlockモジュールを初期化実行\n",
    "net.net3_1.apply(weights_init)\n",
    "net.net3_2.apply(weights_init)\n",
    "\n",
    "\n",
    "print('ネットワーク設定完了')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書オブジェクト\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch.Text[0].to(device)  # 文章\n",
    "                labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # mask作成\n",
    "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "                    input_mask = (inputs != input_pad)\n",
    "\n",
    "                    # Transformerに入力\n",
    "                    outputs = net(inputs, input_mask)\n",
    "                    loss = criterion(outputs, labels)  # 損失を計算\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)  # ラベルを予測。maxの第2引数はnumpyでいうaxis。２つめの返り値はindices。\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 結果の計算\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
    "                    # 正解数の合計を更新\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double(\n",
    "            ) / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習・検証を実行する \n",
    "num_epochs = 15\n",
    "net_trained = train_model(net, dataloaders_dict,\n",
    "                          criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テストデータでの推論\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained.eval()   # モデルを検証モードに\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "for batch in (test_dl):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    \n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    inputs = batch.Text[0].to(device)  # 文章\n",
    "    labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # mask作成\n",
    "        input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "        input_mask = (inputs != input_pad)\n",
    "\n",
    "        # Transformerに入力\n",
    "        outputs = net_trained(inputs, input_mask)\n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測。\n",
    "\n",
    "        # 結果の計算\n",
    "        # 正解数の合計を更新\n",
    "        epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dl.dataset),epoch_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
